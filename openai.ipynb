{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "info = p.get_default_host_api_info()\n",
    "for i in range(info.get(\"deviceCount\")):\n",
    "    if (p.get_device_info_by_host_api_device_index(0, i).get(\"maxInputChannels\")) > 0:\n",
    "        print(\n",
    "            \"Input Device id \",\n",
    "            i,\n",
    "            \" - \",\n",
    "            p.get_device_info_by_host_api_device_index(0, i).get(\"name\"),\n",
    "        )\n",
    "\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "DEVICE_INDEX = 4\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    input_device_index=DEVICE_INDEX,\n",
    "    frames_per_buffer=CHUNK,\n",
    ")\n",
    "\n",
    "print(\"recording\")\n",
    "wf = wave.open(\"./data/recording.wav\", \"wb\")\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "\n",
    "for _ in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    wf.writeframes(stream.read(CHUNK))\n",
    "\n",
    "wf.close()\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "print(\"done recording\")\n",
    "\n",
    "# LEFT HERE\n",
    "# TODO: feed the recording into transcription model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "with open(\"./data/recording.wav\", \"rb\") as f:\n",
    "    response = openai.audio.transcriptions.create(model=\"whisper-1\", file=f)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pyaudio\n",
    "from openai import OpenAI\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "player_stream = pyaudio.PyAudio().open(\n",
    "    format=pyaudio.paInt16, channels=1, rate=24000, output=True\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with openai.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    response_format=\"pcm\",  # similar to WAV, but without a header chunk at the start.\n",
    "    input=\"\"\"I see skies of blue and clouds of white \n",
    "            The bright blessed days, the dark sacred nights \n",
    "            And I think to myself \n",
    "            What a wonderful world\"\"\",\n",
    ") as response:\n",
    "    print(f\"Time to first byte: {int((time.time() - start_time) * 1000)}ms\")\n",
    "    for chunk in response.iter_bytes(chunk_size=1024):\n",
    "        player_stream.write(chunk)\n",
    "\n",
    "print(f\"Done in {int((time.time() - start_time) * 1000)}ms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pyaudio\n",
    "from openai import OpenAI, Stream\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "\n",
    "def say(input: str | Stream):\n",
    "    if isinstance(input, str):\n",
    "        say_string(input)\n",
    "    else:\n",
    "        say_stream(input)\n",
    "\n",
    "\n",
    "def say_stream(input: Stream):\n",
    "    sentence_terminators = [\".\", \"?\", \"!\"]\n",
    "    sentence = \"\"\n",
    "    for chunk in input:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content:\n",
    "            for char in content:\n",
    "                if (\n",
    "                    char not in sentence_terminators\n",
    "                    and sentence[-1:] in sentence_terminators\n",
    "                ):\n",
    "                    # End of sentence\n",
    "                    # This blocks until playback of the sentence is done\n",
    "                    # TODO: continue reading input stream while playing\n",
    "                    say_string(sentence.strip())\n",
    "                    sentence = char\n",
    "                else:\n",
    "                    sentence += char\n",
    "    if sentence:\n",
    "        say_string(sentence.strip())\n",
    "\n",
    "\n",
    "def say_string(input: str):\n",
    "    print(f\"Saying: {input}\")\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "        format=pyaudio.paInt16,\n",
    "        channels=1,\n",
    "        rate=24000,\n",
    "        output=True,\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    with openai.audio.speech.with_streaming_response.create(\n",
    "        model=\"tts-1\", voice=\"alloy\", response_format=\"pcm\", input=input\n",
    "    ) as response:\n",
    "        print(f\"Time to first byte: {int((time.time() - start_time) * 1000)}ms\")\n",
    "        for chunk in response.iter_bytes(chunk_size=1024):\n",
    "            stream.write(chunk)\n",
    "\n",
    "        print(f\"Done in {int((time.time() - start_time) * 1000)}ms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "say(\"\"\"\\\n",
    "I see skies of blue and clouds of white \n",
    "The bright blessed days, the dark sacred nights \n",
    "And I think to myself \n",
    "What a wonderful world\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "start_time = time.time()\n",
    "with openai.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\", voice=\"alloy\", response_format=\"wav\", input=\"Hello, world!\"\n",
    ") as response:\n",
    "    num_chunks = 0\n",
    "    for chunk in response.iter_bytes():\n",
    "        print(f\"{time.time() - start_time:.3f} - {len(chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a short uplifiting poem\"}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "say(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
