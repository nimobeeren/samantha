{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "info = p.get_default_host_api_info()\n",
    "for i in range(info.get(\"deviceCount\")):\n",
    "    if (p.get_device_info_by_host_api_device_index(0, i).get(\"maxInputChannels\")) > 0:\n",
    "        print(\n",
    "            \"Input Device id \",\n",
    "            i,\n",
    "            \" - \",\n",
    "            p.get_device_info_by_host_api_device_index(0, i).get(\"name\"),\n",
    "        )\n",
    "\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "DEVICE_INDEX = 4\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    input_device_index=DEVICE_INDEX,\n",
    "    frames_per_buffer=CHUNK,\n",
    ")\n",
    "\n",
    "print(\"recording\")\n",
    "wf = wave.open(\"./data/recording.wav\", \"wb\")\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "\n",
    "for _ in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    wf.writeframes(stream.read(CHUNK))\n",
    "\n",
    "wf.close()\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "print(\"done recording\")\n",
    "\n",
    "# LEFT HERE\n",
    "# TODO: feed the recording into transcription model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "with open(\"./data/recording.wav\", \"rb\") as f:\n",
    "    response = openai.audio.transcriptions.create(model=\"whisper-1\", file=f)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "from time import sleep\n",
    "\n",
    "import pyaudio\n",
    "import requests\n",
    "from openai import Stream\n",
    "\n",
    "\n",
    "def say(input: str | Stream):\n",
    "    if isinstance(input, str):\n",
    "        say_string(input)\n",
    "    else:\n",
    "        say_stream(input)\n",
    "\n",
    "\n",
    "def say_stream(input: Stream):\n",
    "    sentence_terminators = [\".\", \"?\", \"!\"]\n",
    "    sentence = \"\"\n",
    "    for chunk in input:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content:\n",
    "            for char in content:\n",
    "                if (\n",
    "                    char not in sentence_terminators\n",
    "                    and sentence[-1:] in sentence_terminators\n",
    "                ):\n",
    "                    # End of sentence\n",
    "                    # This blocks until playback of the sentence is done\n",
    "                    # TODO: continue reading input stream while playing\n",
    "                    say_string(sentence.strip())\n",
    "                    sentence = char\n",
    "                else:\n",
    "                    sentence += char\n",
    "    if sentence:\n",
    "        say_string(sentence.strip())\n",
    "\n",
    "\n",
    "def say_string(input: str):\n",
    "    print(f\"Saying: {input}\")\n",
    "    url = \"https://api.openai.com/v1/audio/speech\"\n",
    "    headers = {\n",
    "        \"Authorization\": f'Bearer {os.getenv(\"OPENAI_API_KEY\")}',\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"tts-1\",\n",
    "        \"input\": input,\n",
    "        \"voice\": \"shimmer\",\n",
    "        \"response_format\": \"wav\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "\n",
    "    if response.ok:\n",
    "        with wave.open(response.raw, \"rb\") as wf:\n",
    "\n",
    "            def callback(in_data, frame_count, time_info, status):\n",
    "                data = wf.readframes(frame_count)\n",
    "                # If len(data) is less than requested frame_count, PyAudio automatically\n",
    "                # assumes the stream is finished, and the stream stops.\n",
    "                return (data, pyaudio.paContinue)\n",
    "\n",
    "            p = pyaudio.PyAudio()\n",
    "            stream = p.open(\n",
    "                format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                channels=wf.getnchannels(),\n",
    "                rate=wf.getframerate(),\n",
    "                output=True,\n",
    "                stream_callback=callback,\n",
    "            )\n",
    "\n",
    "            # Wait for stream to finish\n",
    "            while stream.is_active():\n",
    "                sleep(0.1)\n",
    "            stream.close()\n",
    "            p.terminate()\n",
    "    else:\n",
    "        response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "say(\"\"\"\\\n",
    "I can't believe I won the lottery!\n",
    "What should I do with all this money?\n",
    "Should I quit my job and travel the world?\n",
    "The possibilities are endless!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a few sentences ending with multiple ? or !\"}\n",
    "    ],\n",
    "    stream=True,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "say(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
